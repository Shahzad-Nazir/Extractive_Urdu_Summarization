{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEnAH3wPbZet",
        "outputId": "1b9093ac-f93d-4775-ccdd-65674ce49452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average recall is: \n",
            "0.723335812318047\n",
            "average Precision is: \n",
            "0.48963337240031213\n",
            "f-measure average: \n",
            "0.5839708998797685\n",
            "for ROUGE 2\n",
            "ROUGE-2 average Precision is: \n",
            "0.20664836225898273\n",
            "AROUGE-2 average recall is: \n",
            "0.33047871274879526\n",
            "ROUGE-2 f-measure average: \n",
            "0.2542894891306918\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def ROUGE2_pre(g, h):\n",
        "\n",
        "    ac_words1 = g.split(' ')\n",
        "    pro_words1 = h.split(' ')\n",
        "\n",
        "\n",
        "    ac_words = list(nltk.bigrams(ac_words1))\n",
        "    pro_words = list(nltk.bigrams(pro_words1))\n",
        "\n",
        "\n",
        "    count = 0\n",
        "    if len(ac_words) > len(pro_words):\n",
        "        for x in pro_words:\n",
        "            for k in ac_words:\n",
        "               if x == k:\n",
        "                    count= count + 1\n",
        "                    break\n",
        "    elif len(pro_words)>len(ac_words):\n",
        "        for x in ac_words:\n",
        "            for k in pro_words:\n",
        "                if x == k:\n",
        "                    count = count + 1\n",
        "                    break\n",
        "\n",
        "    pre_rouge_2 = count / len(pro_words)\n",
        "\n",
        "    return pre_rouge_2\n",
        "\n",
        "\n",
        "\n",
        "def ROUGE2_re(g, h):\n",
        "\n",
        "\n",
        "    ac_words1 = g.split(' ')\n",
        "    pro_words1 = h.split(' ')\n",
        "\n",
        "\n",
        "    ac_words = list(nltk.bigrams(ac_words1))\n",
        "    pro_words = list(nltk.bigrams(pro_words1))\n",
        "\n",
        "    count = 0\n",
        "    if len(ac_words) > len(pro_words):\n",
        "        for x in pro_words:\n",
        "            for k in ac_words:\n",
        "                if x == k:\n",
        "                    count = count + 1\n",
        "                    break\n",
        "    elif len(pro_words) > len(ac_words):\n",
        "        for x in ac_words:\n",
        "            for k in pro_words:\n",
        "                if x == k:\n",
        "                    count = count + 1\n",
        "                    break\n",
        "\n",
        "    # Storing the final accuracy of Rouge-1\n",
        "    if(len(ac_words)==0):\n",
        "      re_rouge_2 = count / 1\n",
        "    else:\n",
        "      re_rouge_2 = count / len(ac_words)\n",
        "\n",
        "    return re_rouge_2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def ROUGE1_pre(g, h):\n",
        "\n",
        "    ac_words = g.split(' ')\n",
        "    pro_words = h.split(' ')\n",
        "\n",
        "\n",
        "    count = 0\n",
        "    if len(ac_words) > len(pro_words):\n",
        "        for x in pro_words:\n",
        "            for k in ac_words:\n",
        "               if x == k:\n",
        "                    count= count + 1\n",
        "                    break\n",
        "    elif len(pro_words)>len(ac_words):\n",
        "        for x in ac_words:\n",
        "            for k in pro_words:\n",
        "                if x == k:\n",
        "                    count = count + 1\n",
        "                    break\n",
        "\n",
        "\n",
        "    pre_rouge_1 = count / len(pro_words)\n",
        "\n",
        "    return pre_rouge_1\n",
        "\n",
        "\n",
        "def ROUGE1_re(g, h):\n",
        "\n",
        "    ac_words = g.split(' ')\n",
        "    pro_words = h.split(' ')\n",
        "\n",
        "    count = 0\n",
        "    if len(ac_words) > len(pro_words):\n",
        "        for x in pro_words:\n",
        "            for k in ac_words:\n",
        "                if x == k:\n",
        "                    count = count + 1\n",
        "                    break\n",
        "    elif len(pro_words) > len(ac_words):\n",
        "        for x in ac_words:\n",
        "            for k in pro_words:\n",
        "                if x == k:\n",
        "                    count = count + 1\n",
        "                    break\n",
        "\n",
        "    if(len(ac_words)==0):\n",
        "      re_rouge_1 = count / 1\n",
        "    else:\n",
        "      re_rouge_1 = count / len(ac_words)\n",
        "\n",
        "    return re_rouge_1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_summary(data):\n",
        "\n",
        "\n",
        "    data = data.replace('\\r\\n', ' ')\n",
        "    data   = data.split('۔')\n",
        "\n",
        "\n",
        "    rsentencted = \"\"\n",
        "    rankedSentences = textrankTfIdf(data)\n",
        "    orderedSentences = orderSentences(rankedSentences, data, data)\n",
        "    for ordered in orderedSentences:\n",
        "        if ordered != \"\":\n",
        "            rsentencted = rsentencted + str(ordered) +'۔'\n",
        "    return rsentencted\n",
        "\n",
        "\n",
        "\n",
        "def textrankTfIdf(document):\n",
        "\n",
        "    sentences = document\n",
        "    bow_matrix = CountVectorizer().fit_transform(sentences)\n",
        "\n",
        "\n",
        "    normalized = TfidfTransformer().fit_transform(bow_matrix)\n",
        "    similarity_graph = normalized * normalized.T\n",
        "\n",
        "    nx_graph = nx.from_numpy_array((similarity_graph))\n",
        "    scores = nx.pagerank(nx_graph)\n",
        "    return sorted(((scores[i], s) for i, s in enumerate(sentences)),reverse=True)\n",
        "\n",
        "\n",
        "\n",
        "def orderSentences(rankedList, data, initSentences):\n",
        "    index = ['']*len(data)\n",
        "    # print(rankedList)\n",
        "    for eachRanked in rankedList[0:int(math.ceil(0.13*len(rankedList)))]:\n",
        "        sen = eachRanked[1]\n",
        "        index[data.index(sen)] = initSentences[data.index(sen)]\n",
        "        # print(data.index(sen))\n",
        "    return index\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('Urdu_7_Books.csv')\n",
        "\n",
        "\n",
        "X = df.Text\n",
        "y = df.Khulasay\n",
        "z = df.Markazi_Khayal\n",
        "\n",
        "j = 0\n",
        "precount = 1\n",
        "presumscore = 0\n",
        "preavg = 0\n",
        "\n",
        "resumscore = 0\n",
        "reavg = 0\n",
        "\n",
        "f_score = 0\n",
        "f_sums = 0\n",
        "f_avg = 0\n",
        "\n",
        "presumscore2 = 0\n",
        "preavg2 = 0\n",
        "\n",
        "resumscore2 = 0\n",
        "reavg2 = 0\n",
        "\n",
        "f_score2 = 0\n",
        "f_sums2 = 0\n",
        "f_avg2 = 0\n",
        "\n",
        "\n",
        "for x in X:\n",
        "    XC = generate_summary(str(' '+X[j]+' '))\n",
        "    precision = ROUGE1_pre(XC, y[j])\n",
        "    recall = ROUGE1_re(XC, y[j])\n",
        "\n",
        "    presumscore = presumscore + precision\n",
        "    resumscore = resumscore + recall\n",
        "\n",
        "    preavg = presumscore / precount\n",
        "    reavg = resumscore / precount\n",
        "\n",
        "    # ==========ROUGE-2==========================================\n",
        "\n",
        "    precision2 = ROUGE2_pre(XC, y[j])\n",
        "    recall2 = ROUGE2_re(XC, y[j])\n",
        "    # print(XC)\n",
        "\n",
        "    presumscore2 = presumscore2 + precision2\n",
        "    resumscore2 = resumscore2 + recall2\n",
        "\n",
        "    preavg2 = presumscore2 / precount\n",
        "    reavg2 = resumscore2 / precount\n",
        "\n",
        "    precount = precount + 1\n",
        "    j = j + 1\n",
        "\n",
        "f_score = 2 * (preavg * reavg) / (preavg + reavg)\n",
        "\n",
        "f_score2 = 2 * (preavg2 * reavg2) / (preavg2 + reavg2)\n",
        "\n",
        "print(\"average recall is: \")\n",
        "print(reavg)\n",
        "\n",
        "print(\"average Precision is: \")\n",
        "print(preavg)\n",
        "\n",
        "print(\"f-measure average: \")\n",
        "print(f_score)\n",
        "\n",
        "print(\"for ROUGE 2\")\n",
        "\n",
        "print(\"ROUGE-2 average Precision is: \")\n",
        "print(preavg2)\n",
        "\n",
        "print(\"AROUGE-2 average recall is: \")\n",
        "print(reavg2)\n",
        "\n",
        "print(\"ROUGE-2 f-measure average: \")\n",
        "print(f_score2)\n"
      ]
    }
  ]
}