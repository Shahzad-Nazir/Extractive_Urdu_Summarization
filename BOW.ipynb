{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcbIqlmsdqcC",
        "outputId": "25db351a-4c08-48cb-ca41-fd180e28664c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average recall is: \n",
            "0.6736129278369419\n",
            "average Precision is: \n",
            "0.4070054294603765\n",
            "f-measure average: \n",
            "0.5074208061207373\n",
            "for ROUGE 2\n",
            "ROUGE-2 average Precision is: \n",
            "0.15867434072777653\n",
            "AROUGE-2 average recall is: \n",
            "0.27655061524101276\n",
            "ROUGE-2 f-measure average: \n",
            "0.20164968000766714\n"
          ]
        }
      ],
      "source": [
        "import heapq\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "\n",
        "\n",
        "def ROUGE2_pre(g, h):\n",
        "\n",
        "    ac_words1 = g.split(' ')\n",
        "    pro_words1 = h.split(' ')\n",
        "\n",
        "\n",
        "    ac_words = list(nltk.bigrams(ac_words1))\n",
        "    pro_words = list(nltk.bigrams(pro_words1))\n",
        "\n",
        "\n",
        "    count = 0\n",
        "    if len(ac_words) > len(pro_words):\n",
        "        for x in pro_words:\n",
        "            for k in ac_words:\n",
        "               if x == k:\n",
        "                    count= count + 1\n",
        "                    break\n",
        "    elif len(pro_words)>len(ac_words):\n",
        "        for x in ac_words:\n",
        "            for k in pro_words:\n",
        "                if x == k:\n",
        "                    count = count + 1\n",
        "                    break\n",
        "\n",
        "    pre_rouge_2 = count / len(pro_words)\n",
        "\n",
        "    return pre_rouge_2\n",
        "\n",
        "\n",
        "\n",
        "def ROUGE2_re(g, h):\n",
        "\n",
        "\n",
        "    ac_words1 = g.split(' ')\n",
        "    pro_words1 = h.split(' ')\n",
        "\n",
        "\n",
        "    ac_words = list(nltk.bigrams(ac_words1))\n",
        "    pro_words = list(nltk.bigrams(pro_words1))\n",
        "\n",
        "    count = 0\n",
        "    if len(ac_words) > len(pro_words):\n",
        "        for x in pro_words:\n",
        "            for k in ac_words:\n",
        "                if x == k:\n",
        "                    count = count + 1\n",
        "                    break\n",
        "    elif len(pro_words) > len(ac_words):\n",
        "        for x in ac_words:\n",
        "            for k in pro_words:\n",
        "                if x == k:\n",
        "                    count = count + 1\n",
        "                    break\n",
        "\n",
        "    # Storing the final accuracy of Rouge-1\n",
        "    if(len(ac_words)==0):\n",
        "      re_rouge_2 = count / 1\n",
        "    else:\n",
        "      re_rouge_2 = count / len(ac_words)\n",
        "\n",
        "    return re_rouge_2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def ROUGE1_pre(g, h):\n",
        "\n",
        "    ac_words = g.split(' ')\n",
        "    pro_words = h.split(' ')\n",
        "\n",
        "\n",
        "    count = 0\n",
        "    if len(ac_words) > len(pro_words):\n",
        "        for x in pro_words:\n",
        "            for k in ac_words:\n",
        "               if x == k:\n",
        "                    count= count + 1\n",
        "                    break\n",
        "    elif len(pro_words)>len(ac_words):\n",
        "        for x in ac_words:\n",
        "            for k in pro_words:\n",
        "                if x == k:\n",
        "                    count = count + 1\n",
        "                    break\n",
        "\n",
        "\n",
        "    pre_rouge_1 = count / len(pro_words)\n",
        "\n",
        "    return pre_rouge_1\n",
        "\n",
        "\n",
        "def ROUGE1_re(g, h):\n",
        "\n",
        "    ac_words = g.split(' ')\n",
        "    pro_words = h.split(' ')\n",
        "\n",
        "    count = 0\n",
        "    if len(ac_words) > len(pro_words):\n",
        "        for x in pro_words:\n",
        "            for k in ac_words:\n",
        "                if x == k:\n",
        "                    count = count + 1\n",
        "                    break\n",
        "    elif len(pro_words) > len(ac_words):\n",
        "        for x in ac_words:\n",
        "            for k in pro_words:\n",
        "                if x == k:\n",
        "                    count = count + 1\n",
        "                    break\n",
        "\n",
        "    if(len(ac_words)==0):\n",
        "      re_rouge_1 = count / 1\n",
        "    else:\n",
        "      re_rouge_1 = count / len(ac_words)\n",
        "\n",
        "    return re_rouge_1\n",
        "\n",
        "\n",
        "\n",
        "def summarygenerate(text):\n",
        "\n",
        "    te = text.replace('\\r\\n', ' ')\n",
        "\n",
        "    sentences_tokens = te.split('۔')\n",
        "\n",
        "    words_tokens = te.split(' ')\n",
        "\n",
        "    dfsw = pd.read_csv('Stop_words.csv')\n",
        "    stopwords_list = dfsw.s_words.values.tolist()\n",
        "\n",
        "\n",
        "\n",
        "    words_stemm = words_tokens\n",
        "\n",
        "    word_frequencies = {}\n",
        "    for word in words_stemm:\n",
        "        if word not in stopwords_list:\n",
        "            if word not in word_frequencies.keys():\n",
        "                word_frequencies[word] = 1\n",
        "            else:\n",
        "                word_frequencies[word] += 1\n",
        "\n",
        "    maximum_frequency_word = max(word_frequencies.values())\n",
        "\n",
        "    for word in word_frequencies.keys():\n",
        "        word_frequencies[word] = (word_frequencies[word]/maximum_frequency_word)\n",
        "\n",
        "\n",
        "    sentences_scores = {}\n",
        "    wordsCounter = 0.0\n",
        "    for sentence in sentences_tokens:\n",
        "        wr = sentence.split(' ')\n",
        "        for word in wr:\n",
        "            if word in word_frequencies.keys():\n",
        "                wordsCounter += 1;\n",
        "                if sentence not in sentences_scores.keys():\n",
        "                    sentences_scores[sentence] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentences_scores[sentence] += word_frequencies[word]\n",
        "\n",
        "\n",
        "        wordsCounter = 0\n",
        "\n",
        "    summary = heapq.nlargest(7, sentences_scores, key=sentences_scores.get)\n",
        "\n",
        "    ss = ''\n",
        "    for s in summary:\n",
        "        ss = ss + ' ' +'۔' +' ' +s\n",
        "\n",
        "    return ss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('Urdu_7_Books.csv')\n",
        "\n",
        "\n",
        "X = df.Text\n",
        "y = df.Khulasay\n",
        "z = df.Markazi_Khayal\n",
        "\n",
        "j = 0\n",
        "precount = 1\n",
        "presumscore = 0\n",
        "preavg = 0\n",
        "\n",
        "resumscore = 0\n",
        "reavg = 0\n",
        "\n",
        "f_score = 0\n",
        "f_sums = 0\n",
        "f_avg = 0\n",
        "\n",
        "presumscore2 = 0\n",
        "preavg2 = 0\n",
        "\n",
        "resumscore2 = 0\n",
        "reavg2 = 0\n",
        "\n",
        "f_score2 = 0\n",
        "f_sums2 = 0\n",
        "f_avg2 = 0\n",
        "\n",
        "size = 6\n",
        "\n",
        "for x in X:\n",
        "    XC = summarygenerate(str(' '+X[j]+' '))\n",
        "    precision = ROUGE1_pre(XC, y[j])\n",
        "    recall = ROUGE1_re(XC, y[j])\n",
        "\n",
        "    presumscore = presumscore + precision\n",
        "    resumscore = resumscore + recall\n",
        "\n",
        "    preavg = presumscore / precount\n",
        "    reavg = resumscore / precount\n",
        "\n",
        "    # ==========ROUGE-2==========================================\n",
        "\n",
        "    precision2 = ROUGE2_pre(XC, y[j])\n",
        "    recall2 = ROUGE2_re(XC, y[j])\n",
        "    # print(XC)\n",
        "\n",
        "    presumscore2 = presumscore2 + precision2\n",
        "    resumscore2 = resumscore2 + recall2\n",
        "\n",
        "    preavg2 = presumscore2 / precount\n",
        "    reavg2 = resumscore2 / precount\n",
        "\n",
        "    precount = precount + 1\n",
        "    j = j + 1\n",
        "\n",
        "f_score = 2 * (preavg * reavg) / (preavg + reavg)\n",
        "\n",
        "f_score2 = 2 * (preavg2 * reavg2) / (preavg2 + reavg2)\n",
        "\n",
        "print(\"average recall is: \")\n",
        "print(reavg)\n",
        "\n",
        "print(\"average Precision is: \")\n",
        "print(preavg)\n",
        "\n",
        "print(\"f-measure average: \")\n",
        "print(f_score)\n",
        "\n",
        "print(\"for ROUGE 2\")\n",
        "\n",
        "print(\"ROUGE-2 average Precision is: \")\n",
        "print(preavg2)\n",
        "\n",
        "print(\"AROUGE-2 average recall is: \")\n",
        "print(reavg2)\n",
        "\n",
        "print(\"ROUGE-2 f-measure average: \")\n",
        "print(f_score2)\n"
      ]
    }
  ]
}